gcloud dataproc batches submit --project atmo-flow --region us-central1 pyspark --batch atmoflow-spark-batch gs://atmoflow-temp/pyspark_code/dataproc_pyspark.py --version 2.2 --subnet default --properties spark.jars.packages=org.apache.spark:spark-streaming-pubsub_2.12:3.4.0,spark.jars.repositories=https://repository.apache.org/content/repositories/releases/,spark.executorEnv.PROJECT_ID=atmo-flow,spark.executorEnv.REGION=us-central1,spark.executorEnv.LATITUDE=40.7128,spark.executorEnv.LONGITUDE=-74.0060,spark.executorEnv.HISTORICAL_BUCKET=atmoflow-historical-data,spark.executorEnv.TEMP_BUCKET=atmoflow-temp,spark.executorEnv.AIR_QUALITY_PREFIX=air-quality-data,spark.executorEnv.WEATHER_PREFIX=weather-data,spark.executorEnv.AIR_QUALITY_TOPIC=projects/atmo-flow/topics/air-quality-raw-data,spark.executorEnv.WEATHER_TOPIC=projects/atmo-flow/topics/weather-raw-data,spark.executorEnv.DEAD_LETTER_TOPIC=projects/atmo-flow/topics/dead-letter-queue,spark.executorEnv.DATASET_ID=weather_air_quality,spark.executorEnv.AIR_QUALITY_FACT_TABLE=AirQualityFact,spark.executorEnv.WEATHER_FACT_TABLE=WeatherFact,spark.executorEnv.AIR_QUALITY_STATUS_DIM_TABLE=AirQualityStatusDim,spark.executorEnv.LOCATION_DIM_TABLE=LocationDim,spark.executorEnv.TIME_DIM_TABLE=TimeDim,spark.executorEnv.WEATHER_CONDITION_DIM_TABLE=WeatherConditionDim,spark.executorEnv.HARMONIZED_DATA_TABLE=HarmonizedData,spark.dataproc.driver.compute.tier=standard,spark.dataproc.executor.compute.tier=standard,spark.dataproc.appContext.enabled=true

